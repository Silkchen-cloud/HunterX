# 部署指南

本文档介绍如何将招聘Agent部署到GitHub并设置自动化运行。

## GitHub发布

### 1. 创建GitHub仓库

1. 登录GitHub账户
2. 点击右上角的 "+" 按钮，选择 "New repository"
3. 填写仓库信息：
   - Repository name: `recruitment-agent`
   - Description: `自动化招聘Agent - 智能搜索和管理候选人`
   - 选择 Public 或 Private
   - 不要初始化README、.gitignore或LICENSE（我们已经有了）

### 2. 推送代码到GitHub

```bash
# 添加远程仓库
git remote add origin https://github.com/YOUR_USERNAME/recruitment-agent.git

# 推送代码
git branch -M main
git push -u origin main
```

### 3. 设置仓库描述和标签

在GitHub仓库页面：
1. 点击右侧的 "About" 齿轮图标
2. 添加描述：`自动化招聘Agent，支持LinkedIn、Facebook、X平台的候选人搜索和Notion集成`
3. 添加标签：`recruitment`, `automation`, `linkedin`, `notion`, `python`, `scraping`
4. 添加网站链接（如果有）

## 云平台部署

### 1. AWS Lambda部署

#### 准备部署包
```bash
# 创建部署目录
mkdir lambda-deployment
cd lambda-deployment

# 复制项目文件
cp -r ../recruitment_agent/* .

# 安装依赖到当前目录
pip install -r requirements.txt -t .

# 创建Lambda处理函数
cat > lambda_handler.py << 'EOF'
import json
import os
from recruitment_agent import RecruitmentAgent

def lambda_handler(event, context):
    """AWS Lambda处理函数"""
    try:
        # 从环境变量获取配置
        keywords = event.get('keywords', os.getenv('SEARCH_KEYWORDS', 'software engineer').split(','))
        locations = event.get('locations', os.getenv('SEARCH_LOCATIONS', 'Beijing,Shanghai').split(','))
        max_results = event.get('max_results', int(os.getenv('MAX_RESULTS_PER_PLATFORM', '50')))
        
        # 运行Agent
        agent = RecruitmentAgent()
        results = agent.run(
            keywords=keywords,
            locations=locations,
            max_results_per_platform=max_results
        )
        
        return {
            'statusCode': 200,
            'body': json.dumps({
                'message': 'Agent运行成功',
                'candidates_found': len(results),
                'results': results[:10]  # 只返回前10个结果
            }, ensure_ascii=False)
        }
        
    except Exception as e:
        return {
            'statusCode': 500,
            'body': json.dumps({
                'error': str(e)
            }, ensure_ascii=False)
        }
EOF

# 打包
zip -r recruitment-agent-lambda.zip .
```

#### 部署到AWS Lambda
1. 登录AWS控制台
2. 进入Lambda服务
3. 创建新函数
4. 上传deployment包
5. 设置环境变量
6. 配置触发器（CloudWatch Events for scheduling）

### 2. Google Cloud Functions部署

#### 准备部署文件
```bash
# 创建main.py作为入口点
cat > main.py << 'EOF'
import functions_framework
from recruitment_agent import RecruitmentAgent

@functions_framework.http
def recruitment_agent_http(request):
    """HTTP Cloud Function入口点"""
    try:
        agent = RecruitmentAgent()
        results = agent.run()
        
        return {
            'status': 'success',
            'candidates_found': len(results)
        }
    except Exception as e:
        return {'status': 'error', 'message': str(e)}, 500

@functions_framework.cloud_event
def recruitment_agent_scheduled(cloud_event):
    """定时触发的Cloud Function"""
    try:
        agent = RecruitmentAgent()
        results = agent.run()
        print(f"找到 {len(results)} 个候选人")
    except Exception as e:
        print(f"错误: {e}")
EOF

# 部署
gcloud functions deploy recruitment-agent \
    --runtime python311 \
    --trigger-http \
    --entry-point recruitment_agent_http \
    --set-env-vars NOTION_API_KEY=your_key,NOTION_DATABASE_ID=your_id
```

### 3. Heroku部署

#### 准备Heroku文件
```bash
# 创建Procfile
echo "worker: python main.py schedule --cron '0 9 * * *'" > Procfile

# 创建runtime.txt
echo "python-3.11.0" > runtime.txt

# 创建app.json
cat > app.json << 'EOF'
{
  "name": "Recruitment Agent",
  "description": "自动化招聘候选人搜索Agent",
  "repository": "https://github.com/YOUR_USERNAME/recruitment-agent",
  "keywords": ["python", "recruitment", "automation", "notion"],
  "env": {
    "NOTION_API_KEY": {
      "description": "Notion API密钥",
      "required": true
    },
    "NOTION_DATABASE_ID": {
      "description": "Notion数据库ID",
      "required": true
    },
    "SEARCH_KEYWORDS": {
      "description": "搜索关键词",
      "value": "software engineer,data scientist"
    }
  }
}
EOF
```

#### 部署到Heroku
```bash
# 安装Heroku CLI
# 登录Heroku
heroku login

# 创建应用
heroku create your-recruitment-agent

# 设置环境变量
heroku config:set NOTION_API_KEY=your_key
heroku config:set NOTION_DATABASE_ID=your_id

# 推送代码
git push heroku main

# 启动worker
heroku ps:scale worker=1
```

### 4. Docker部署

#### 创建Dockerfile
```dockerfile
FROM python:3.11-slim

# 安装系统依赖
RUN apt-get update && apt-get install -y \
    wget \
    gnupg \
    unzip \
    curl \
    && rm -rf /var/lib/apt/lists/*

# 安装Chrome
RUN wget -q -O - https://dl.google.com/linux/linux_signing_key.pub | apt-key add - \
    && echo "deb [arch=amd64] http://dl.google.com/linux/chrome/deb/ stable main" >> /etc/apt/sources.list.d/google-chrome.list \
    && apt-get update \
    && apt-get install -y google-chrome-stable \
    && rm -rf /var/lib/apt/lists/*

# 设置工作目录
WORKDIR /app

# 复制依赖文件
COPY requirements.txt .

# 安装Python依赖
RUN pip install --no-cache-dir -r requirements.txt

# 复制应用代码
COPY . .

# 设置环境变量
ENV PYTHONPATH=/app
ENV DISPLAY=:99

# 暴露端口（如果需要Web界面）
EXPOSE 8000

# 启动命令
CMD ["python", "main.py", "schedule", "--cron", "0 9 * * *"]
```

#### 构建和运行
```bash
# 构建镜像
docker build -t recruitment-agent .

# 运行容器
docker run -d \
  --name recruitment-agent \
  -e NOTION_API_KEY=your_key \
  -e NOTION_DATABASE_ID=your_id \
  recruitment-agent

# 查看日志
docker logs -f recruitment-agent
```

## GitHub Actions自动化

### 1. 创建工作流文件

```bash
mkdir -p .github/workflows
```

```yaml
# .github/workflows/recruitment-agent.yml
name: Recruitment Agent

on:
  schedule:
    # 每天UTC时间1点运行 (北京时间9点)
    - cron: '0 1 * * *'
  workflow_dispatch:  # 允许手动触发

jobs:
  run-agent:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v3
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    
    - name: Run recruitment agent
      env:
        NOTION_API_KEY: ${{ secrets.NOTION_API_KEY }}
        NOTION_DATABASE_ID: ${{ secrets.NOTION_DATABASE_ID }}
        TWITTER_BEARER_TOKEN: ${{ secrets.TWITTER_BEARER_TOKEN }}
        FACEBOOK_ACCESS_TOKEN: ${{ secrets.FACEBOOK_ACCESS_TOKEN }}
        SEARCH_KEYWORDS: ${{ vars.SEARCH_KEYWORDS }}
        SEARCH_LOCATIONS: ${{ vars.SEARCH_LOCATIONS }}
      run: |
        python main.py run
    
    - name: Upload logs
      if: always()
      uses: actions/upload-artifact@v3
      with:
        name: agent-logs
        path: '*.log'
```

### 2. 设置GitHub Secrets

在GitHub仓库设置中添加以下Secrets：
- `NOTION_API_KEY`
- `NOTION_DATABASE_ID`
- `TWITTER_BEARER_TOKEN`
- `FACEBOOK_ACCESS_TOKEN`

### 3. 设置GitHub Variables

在GitHub仓库设置中添加以下Variables：
- `SEARCH_KEYWORDS`: `software engineer,data scientist`
- `SEARCH_LOCATIONS`: `Beijing,Shanghai,Shenzhen`

## 监控和维护

### 1. 日志监控

#### CloudWatch (AWS)
```python
import boto3
import logging

# 配置CloudWatch日志
cloudwatch_logs = boto3.client('logs')

class CloudWatchHandler(logging.Handler):
    def __init__(self, log_group, log_stream):
        super().__init__()
        self.log_group = log_group
        self.log_stream = log_stream
    
    def emit(self, record):
        message = self.format(record)
        cloudwatch_logs.put_log_events(
            logGroupName=self.log_group,
            logStreamName=self.log_stream,
            logEvents=[{
                'timestamp': int(record.created * 1000),
                'message': message
            }]
        )

# 在logger.py中添加
handler = CloudWatchHandler('/aws/lambda/recruitment-agent', 'main')
logger.addHandler(handler)
```

#### Google Cloud Logging
```python
from google.cloud import logging as gcp_logging

# 配置Google Cloud Logging
client = gcp_logging.Client()
client.setup_logging()

# 日志会自动发送到Google Cloud
```

### 2. 错误告警

#### 邮件告警
```python
import smtplib
from email.mime.text import MIMEText

def send_alert(subject, message):
    """发送告警邮件"""
    msg = MIMEText(message)
    msg['Subject'] = subject
    msg['From'] = 'agent@yourcompany.com'
    msg['To'] = 'admin@yourcompany.com'
    
    server = smtplib.SMTP('smtp.gmail.com', 587)
    server.starttls()
    server.login('your_email', 'your_password')
    server.send_message(msg)
    server.quit()

# 在异常处理中调用
try:
    agent.run()
except Exception as e:
    send_alert('Agent运行失败', f'错误信息: {str(e)}')
    raise
```

#### Slack告警
```python
import requests

def send_slack_alert(message):
    """发送Slack告警"""
    webhook_url = 'https://hooks.slack.com/services/YOUR/SLACK/WEBHOOK'
    payload = {
        'text': f'🚨 招聘Agent告警: {message}',
        'channel': '#alerts',
        'username': 'Recruitment Agent'
    }
    requests.post(webhook_url, json=payload)
```

### 3. 性能监控

#### 添加指标收集
```python
import time
import json
from datetime import datetime

class MetricsCollector:
    def __init__(self):
        self.metrics = []
    
    def record_run(self, start_time, end_time, candidates_found, platform_stats):
        """记录运行指标"""
        metric = {
            'timestamp': datetime.now().isoformat(),
            'duration_seconds': end_time - start_time,
            'candidates_found': candidates_found,
            'platform_stats': platform_stats
        }
        self.metrics.append(metric)
        
        # 保存到文件
        with open('metrics.json', 'w') as f:
            json.dump(self.metrics, f, indent=2)
    
    def get_average_performance(self, days=7):
        """获取平均性能指标"""
        recent_metrics = self.metrics[-days:]
        if not recent_metrics:
            return None
        
        avg_duration = sum(m['duration_seconds'] for m in recent_metrics) / len(recent_metrics)
        avg_candidates = sum(m['candidates_found'] for m in recent_metrics) / len(recent_metrics)
        
        return {
            'avg_duration_seconds': avg_duration,
            'avg_candidates_found': avg_candidates,
            'total_runs': len(recent_metrics)
        }
```

## 安全考虑

### 1. API密钥管理

- 使用环境变量存储敏感信息
- 定期轮换API密钥
- 限制API密钥权限
- 使用密钥管理服务（AWS Secrets Manager、Azure Key Vault等）

### 2. 网络安全

- 使用HTTPS进行所有API调用
- 配置防火墙规则
- 使用VPN或私有网络
- 启用访问日志

### 3. 数据保护

- 加密存储敏感数据
- 遵守数据保护法规（GDPR、CCPA等）
- 定期备份数据
- 实施数据保留政策

## 故障恢复

### 1. 备份策略

```bash
# 自动备份脚本
#!/bin/bash
DATE=$(date +%Y%m%d_%H%M%S)
BACKUP_DIR="/backups/recruitment-agent"

# 备份配置
cp .env "$BACKUP_DIR/config_$DATE.env"

# 备份Notion数据
python -c "
from notion_integration import NotionIntegration
import json
notion = NotionIntegration()
data = notion.get_all_candidates()
with open('$BACKUP_DIR/notion_data_$DATE.json', 'w') as f:
    json.dump(data, f, indent=2, ensure_ascii=False)
"

# 清理旧备份（保留30天）
find "$BACKUP_DIR" -name "*.json" -mtime +30 -delete
find "$BACKUP_DIR" -name "*.env" -mtime +30 -delete
```

### 2. 恢复流程

```python
def restore_from_backup(backup_file):
    """从备份恢复数据"""
    import json
    from notion_integration import NotionIntegration
    from models import Candidate
    
    # 读取备份数据
    with open(backup_file, 'r') as f:
        backup_data = json.load(f)
    
    # 恢复到Notion
    notion = NotionIntegration()
    for item in backup_data:
        # 转换为Candidate对象
        candidate = Candidate.from_notion_data(item)
        # 重新创建页面
        notion.create_candidate_page(candidate)
```

---

部署完成后，建议定期检查系统运行状态，监控性能指标，并根据实际使用情况调整配置参数。

