# éƒ¨ç½²æŒ‡å—

æœ¬æ–‡æ¡£ä»‹ç»å¦‚ä½•å°†æ‹›è˜Agentéƒ¨ç½²åˆ°GitHubå¹¶è®¾ç½®è‡ªåŠ¨åŒ–è¿è¡Œã€‚

## GitHubå‘å¸ƒ

### 1. åˆ›å»ºGitHubä»“åº“

1. ç™»å½•GitHubè´¦æˆ·
2. ç‚¹å‡»å³ä¸Šè§’çš„ "+" æŒ‰é’®ï¼Œé€‰æ‹© "New repository"
3. å¡«å†™ä»“åº“ä¿¡æ¯ï¼š
   - Repository name: `recruitment-agent`
   - Description: `è‡ªåŠ¨åŒ–æ‹›è˜Agent - æ™ºèƒ½æœç´¢å’Œç®¡ç†å€™é€‰äºº`
   - é€‰æ‹© Public æˆ– Private
   - ä¸è¦åˆå§‹åŒ–READMEã€.gitignoreæˆ–LICENSEï¼ˆæˆ‘ä»¬å·²ç»æœ‰äº†ï¼‰

### 2. æ¨é€ä»£ç åˆ°GitHub

```bash
# æ·»åŠ è¿œç¨‹ä»“åº“
git remote add origin https://github.com/YOUR_USERNAME/recruitment-agent.git

# æ¨é€ä»£ç 
git branch -M main
git push -u origin main
```

### 3. è®¾ç½®ä»“åº“æè¿°å’Œæ ‡ç­¾

åœ¨GitHubä»“åº“é¡µé¢ï¼š
1. ç‚¹å‡»å³ä¾§çš„ "About" é½¿è½®å›¾æ ‡
2. æ·»åŠ æè¿°ï¼š`è‡ªåŠ¨åŒ–æ‹›è˜Agentï¼Œæ”¯æŒLinkedInã€Facebookã€Xå¹³å°çš„å€™é€‰äººæœç´¢å’ŒNotioné›†æˆ`
3. æ·»åŠ æ ‡ç­¾ï¼š`recruitment`, `automation`, `linkedin`, `notion`, `python`, `scraping`
4. æ·»åŠ ç½‘ç«™é“¾æ¥ï¼ˆå¦‚æœæœ‰ï¼‰

## äº‘å¹³å°éƒ¨ç½²

### 1. AWS Lambdaéƒ¨ç½²

#### å‡†å¤‡éƒ¨ç½²åŒ…
```bash
# åˆ›å»ºéƒ¨ç½²ç›®å½•
mkdir lambda-deployment
cd lambda-deployment

# å¤åˆ¶é¡¹ç›®æ–‡ä»¶
cp -r ../recruitment_agent/* .

# å®‰è£…ä¾èµ–åˆ°å½“å‰ç›®å½•
pip install -r requirements.txt -t .

# åˆ›å»ºLambdaå¤„ç†å‡½æ•°
cat > lambda_handler.py << 'EOF'
import json
import os
from recruitment_agent import RecruitmentAgent

def lambda_handler(event, context):
    """AWS Lambdaå¤„ç†å‡½æ•°"""
    try:
        # ä»ç¯å¢ƒå˜é‡è·å–é…ç½®
        keywords = event.get('keywords', os.getenv('SEARCH_KEYWORDS', 'software engineer').split(','))
        locations = event.get('locations', os.getenv('SEARCH_LOCATIONS', 'Beijing,Shanghai').split(','))
        max_results = event.get('max_results', int(os.getenv('MAX_RESULTS_PER_PLATFORM', '50')))
        
        # è¿è¡ŒAgent
        agent = RecruitmentAgent()
        results = agent.run(
            keywords=keywords,
            locations=locations,
            max_results_per_platform=max_results
        )
        
        return {
            'statusCode': 200,
            'body': json.dumps({
                'message': 'Agentè¿è¡ŒæˆåŠŸ',
                'candidates_found': len(results),
                'results': results[:10]  # åªè¿”å›å‰10ä¸ªç»“æœ
            }, ensure_ascii=False)
        }
        
    except Exception as e:
        return {
            'statusCode': 500,
            'body': json.dumps({
                'error': str(e)
            }, ensure_ascii=False)
        }
EOF

# æ‰“åŒ…
zip -r recruitment-agent-lambda.zip .
```

#### éƒ¨ç½²åˆ°AWS Lambda
1. ç™»å½•AWSæ§åˆ¶å°
2. è¿›å…¥LambdaæœåŠ¡
3. åˆ›å»ºæ–°å‡½æ•°
4. ä¸Šä¼ deploymentåŒ…
5. è®¾ç½®ç¯å¢ƒå˜é‡
6. é…ç½®è§¦å‘å™¨ï¼ˆCloudWatch Events for schedulingï¼‰

### 2. Google Cloud Functionséƒ¨ç½²

#### å‡†å¤‡éƒ¨ç½²æ–‡ä»¶
```bash
# åˆ›å»ºmain.pyä½œä¸ºå…¥å£ç‚¹
cat > main.py << 'EOF'
import functions_framework
from recruitment_agent import RecruitmentAgent

@functions_framework.http
def recruitment_agent_http(request):
    """HTTP Cloud Functionå…¥å£ç‚¹"""
    try:
        agent = RecruitmentAgent()
        results = agent.run()
        
        return {
            'status': 'success',
            'candidates_found': len(results)
        }
    except Exception as e:
        return {'status': 'error', 'message': str(e)}, 500

@functions_framework.cloud_event
def recruitment_agent_scheduled(cloud_event):
    """å®šæ—¶è§¦å‘çš„Cloud Function"""
    try:
        agent = RecruitmentAgent()
        results = agent.run()
        print(f"æ‰¾åˆ° {len(results)} ä¸ªå€™é€‰äºº")
    except Exception as e:
        print(f"é”™è¯¯: {e}")
EOF

# éƒ¨ç½²
gcloud functions deploy recruitment-agent \
    --runtime python311 \
    --trigger-http \
    --entry-point recruitment_agent_http \
    --set-env-vars NOTION_API_KEY=your_key,NOTION_DATABASE_ID=your_id
```

### 3. Herokuéƒ¨ç½²

#### å‡†å¤‡Herokuæ–‡ä»¶
```bash
# åˆ›å»ºProcfile
echo "worker: python main.py schedule --cron '0 9 * * *'" > Procfile

# åˆ›å»ºruntime.txt
echo "python-3.11.0" > runtime.txt

# åˆ›å»ºapp.json
cat > app.json << 'EOF'
{
  "name": "Recruitment Agent",
  "description": "è‡ªåŠ¨åŒ–æ‹›è˜å€™é€‰äººæœç´¢Agent",
  "repository": "https://github.com/YOUR_USERNAME/recruitment-agent",
  "keywords": ["python", "recruitment", "automation", "notion"],
  "env": {
    "NOTION_API_KEY": {
      "description": "Notion APIå¯†é’¥",
      "required": true
    },
    "NOTION_DATABASE_ID": {
      "description": "Notionæ•°æ®åº“ID",
      "required": true
    },
    "SEARCH_KEYWORDS": {
      "description": "æœç´¢å…³é”®è¯",
      "value": "software engineer,data scientist"
    }
  }
}
EOF
```

#### éƒ¨ç½²åˆ°Heroku
```bash
# å®‰è£…Heroku CLI
# ç™»å½•Heroku
heroku login

# åˆ›å»ºåº”ç”¨
heroku create your-recruitment-agent

# è®¾ç½®ç¯å¢ƒå˜é‡
heroku config:set NOTION_API_KEY=your_key
heroku config:set NOTION_DATABASE_ID=your_id

# æ¨é€ä»£ç 
git push heroku main

# å¯åŠ¨worker
heroku ps:scale worker=1
```

### 4. Dockeréƒ¨ç½²

#### åˆ›å»ºDockerfile
```dockerfile
FROM python:3.11-slim

# å®‰è£…ç³»ç»Ÿä¾èµ–
RUN apt-get update && apt-get install -y \
    wget \
    gnupg \
    unzip \
    curl \
    && rm -rf /var/lib/apt/lists/*

# å®‰è£…Chrome
RUN wget -q -O - https://dl.google.com/linux/linux_signing_key.pub | apt-key add - \
    && echo "deb [arch=amd64] http://dl.google.com/linux/chrome/deb/ stable main" >> /etc/apt/sources.list.d/google-chrome.list \
    && apt-get update \
    && apt-get install -y google-chrome-stable \
    && rm -rf /var/lib/apt/lists/*

# è®¾ç½®å·¥ä½œç›®å½•
WORKDIR /app

# å¤åˆ¶ä¾èµ–æ–‡ä»¶
COPY requirements.txt .

# å®‰è£…Pythonä¾èµ–
RUN pip install --no-cache-dir -r requirements.txt

# å¤åˆ¶åº”ç”¨ä»£ç 
COPY . .

# è®¾ç½®ç¯å¢ƒå˜é‡
ENV PYTHONPATH=/app
ENV DISPLAY=:99

# æš´éœ²ç«¯å£ï¼ˆå¦‚æœéœ€è¦Webç•Œé¢ï¼‰
EXPOSE 8000

# å¯åŠ¨å‘½ä»¤
CMD ["python", "main.py", "schedule", "--cron", "0 9 * * *"]
```

#### æ„å»ºå’Œè¿è¡Œ
```bash
# æ„å»ºé•œåƒ
docker build -t recruitment-agent .

# è¿è¡Œå®¹å™¨
docker run -d \
  --name recruitment-agent \
  -e NOTION_API_KEY=your_key \
  -e NOTION_DATABASE_ID=your_id \
  recruitment-agent

# æŸ¥çœ‹æ—¥å¿—
docker logs -f recruitment-agent
```

## GitHub Actionsè‡ªåŠ¨åŒ–

### 1. åˆ›å»ºå·¥ä½œæµæ–‡ä»¶

```bash
mkdir -p .github/workflows
```

```yaml
# .github/workflows/recruitment-agent.yml
name: Recruitment Agent

on:
  schedule:
    # æ¯å¤©UTCæ—¶é—´1ç‚¹è¿è¡Œ (åŒ—äº¬æ—¶é—´9ç‚¹)
    - cron: '0 1 * * *'
  workflow_dispatch:  # å…è®¸æ‰‹åŠ¨è§¦å‘

jobs:
  run-agent:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v3
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    
    - name: Run recruitment agent
      env:
        NOTION_API_KEY: ${{ secrets.NOTION_API_KEY }}
        NOTION_DATABASE_ID: ${{ secrets.NOTION_DATABASE_ID }}
        TWITTER_BEARER_TOKEN: ${{ secrets.TWITTER_BEARER_TOKEN }}
        FACEBOOK_ACCESS_TOKEN: ${{ secrets.FACEBOOK_ACCESS_TOKEN }}
        SEARCH_KEYWORDS: ${{ vars.SEARCH_KEYWORDS }}
        SEARCH_LOCATIONS: ${{ vars.SEARCH_LOCATIONS }}
      run: |
        python main.py run
    
    - name: Upload logs
      if: always()
      uses: actions/upload-artifact@v3
      with:
        name: agent-logs
        path: '*.log'
```

### 2. è®¾ç½®GitHub Secrets

åœ¨GitHubä»“åº“è®¾ç½®ä¸­æ·»åŠ ä»¥ä¸‹Secretsï¼š
- `NOTION_API_KEY`
- `NOTION_DATABASE_ID`
- `TWITTER_BEARER_TOKEN`
- `FACEBOOK_ACCESS_TOKEN`

### 3. è®¾ç½®GitHub Variables

åœ¨GitHubä»“åº“è®¾ç½®ä¸­æ·»åŠ ä»¥ä¸‹Variablesï¼š
- `SEARCH_KEYWORDS`: `software engineer,data scientist`
- `SEARCH_LOCATIONS`: `Beijing,Shanghai,Shenzhen`

## ç›‘æ§å’Œç»´æŠ¤

### 1. æ—¥å¿—ç›‘æ§

#### CloudWatch (AWS)
```python
import boto3
import logging

# é…ç½®CloudWatchæ—¥å¿—
cloudwatch_logs = boto3.client('logs')

class CloudWatchHandler(logging.Handler):
    def __init__(self, log_group, log_stream):
        super().__init__()
        self.log_group = log_group
        self.log_stream = log_stream
    
    def emit(self, record):
        message = self.format(record)
        cloudwatch_logs.put_log_events(
            logGroupName=self.log_group,
            logStreamName=self.log_stream,
            logEvents=[{
                'timestamp': int(record.created * 1000),
                'message': message
            }]
        )

# åœ¨logger.pyä¸­æ·»åŠ 
handler = CloudWatchHandler('/aws/lambda/recruitment-agent', 'main')
logger.addHandler(handler)
```

#### Google Cloud Logging
```python
from google.cloud import logging as gcp_logging

# é…ç½®Google Cloud Logging
client = gcp_logging.Client()
client.setup_logging()

# æ—¥å¿—ä¼šè‡ªåŠ¨å‘é€åˆ°Google Cloud
```

### 2. é”™è¯¯å‘Šè­¦

#### é‚®ä»¶å‘Šè­¦
```python
import smtplib
from email.mime.text import MIMEText

def send_alert(subject, message):
    """å‘é€å‘Šè­¦é‚®ä»¶"""
    msg = MIMEText(message)
    msg['Subject'] = subject
    msg['From'] = 'agent@yourcompany.com'
    msg['To'] = 'admin@yourcompany.com'
    
    server = smtplib.SMTP('smtp.gmail.com', 587)
    server.starttls()
    server.login('your_email', 'your_password')
    server.send_message(msg)
    server.quit()

# åœ¨å¼‚å¸¸å¤„ç†ä¸­è°ƒç”¨
try:
    agent.run()
except Exception as e:
    send_alert('Agentè¿è¡Œå¤±è´¥', f'é”™è¯¯ä¿¡æ¯: {str(e)}')
    raise
```

#### Slackå‘Šè­¦
```python
import requests

def send_slack_alert(message):
    """å‘é€Slackå‘Šè­¦"""
    webhook_url = 'https://hooks.slack.com/services/YOUR/SLACK/WEBHOOK'
    payload = {
        'text': f'ğŸš¨ æ‹›è˜Agentå‘Šè­¦: {message}',
        'channel': '#alerts',
        'username': 'Recruitment Agent'
    }
    requests.post(webhook_url, json=payload)
```

### 3. æ€§èƒ½ç›‘æ§

#### æ·»åŠ æŒ‡æ ‡æ”¶é›†
```python
import time
import json
from datetime import datetime

class MetricsCollector:
    def __init__(self):
        self.metrics = []
    
    def record_run(self, start_time, end_time, candidates_found, platform_stats):
        """è®°å½•è¿è¡ŒæŒ‡æ ‡"""
        metric = {
            'timestamp': datetime.now().isoformat(),
            'duration_seconds': end_time - start_time,
            'candidates_found': candidates_found,
            'platform_stats': platform_stats
        }
        self.metrics.append(metric)
        
        # ä¿å­˜åˆ°æ–‡ä»¶
        with open('metrics.json', 'w') as f:
            json.dump(self.metrics, f, indent=2)
    
    def get_average_performance(self, days=7):
        """è·å–å¹³å‡æ€§èƒ½æŒ‡æ ‡"""
        recent_metrics = self.metrics[-days:]
        if not recent_metrics:
            return None
        
        avg_duration = sum(m['duration_seconds'] for m in recent_metrics) / len(recent_metrics)
        avg_candidates = sum(m['candidates_found'] for m in recent_metrics) / len(recent_metrics)
        
        return {
            'avg_duration_seconds': avg_duration,
            'avg_candidates_found': avg_candidates,
            'total_runs': len(recent_metrics)
        }
```

## å®‰å…¨è€ƒè™‘

### 1. APIå¯†é’¥ç®¡ç†

- ä½¿ç”¨ç¯å¢ƒå˜é‡å­˜å‚¨æ•æ„Ÿä¿¡æ¯
- å®šæœŸè½®æ¢APIå¯†é’¥
- é™åˆ¶APIå¯†é’¥æƒé™
- ä½¿ç”¨å¯†é’¥ç®¡ç†æœåŠ¡ï¼ˆAWS Secrets Managerã€Azure Key Vaultç­‰ï¼‰

### 2. ç½‘ç»œå®‰å…¨

- ä½¿ç”¨HTTPSè¿›è¡Œæ‰€æœ‰APIè°ƒç”¨
- é…ç½®é˜²ç«å¢™è§„åˆ™
- ä½¿ç”¨VPNæˆ–ç§æœ‰ç½‘ç»œ
- å¯ç”¨è®¿é—®æ—¥å¿—

### 3. æ•°æ®ä¿æŠ¤

- åŠ å¯†å­˜å‚¨æ•æ„Ÿæ•°æ®
- éµå®ˆæ•°æ®ä¿æŠ¤æ³•è§„ï¼ˆGDPRã€CCPAç­‰ï¼‰
- å®šæœŸå¤‡ä»½æ•°æ®
- å®æ–½æ•°æ®ä¿ç•™æ”¿ç­–

## æ•…éšœæ¢å¤

### 1. å¤‡ä»½ç­–ç•¥

```bash
# è‡ªåŠ¨å¤‡ä»½è„šæœ¬
#!/bin/bash
DATE=$(date +%Y%m%d_%H%M%S)
BACKUP_DIR="/backups/recruitment-agent"

# å¤‡ä»½é…ç½®
cp .env "$BACKUP_DIR/config_$DATE.env"

# å¤‡ä»½Notionæ•°æ®
python -c "
from notion_integration import NotionIntegration
import json
notion = NotionIntegration()
data = notion.get_all_candidates()
with open('$BACKUP_DIR/notion_data_$DATE.json', 'w') as f:
    json.dump(data, f, indent=2, ensure_ascii=False)
"

# æ¸…ç†æ—§å¤‡ä»½ï¼ˆä¿ç•™30å¤©ï¼‰
find "$BACKUP_DIR" -name "*.json" -mtime +30 -delete
find "$BACKUP_DIR" -name "*.env" -mtime +30 -delete
```

### 2. æ¢å¤æµç¨‹

```python
def restore_from_backup(backup_file):
    """ä»å¤‡ä»½æ¢å¤æ•°æ®"""
    import json
    from notion_integration import NotionIntegration
    from models import Candidate
    
    # è¯»å–å¤‡ä»½æ•°æ®
    with open(backup_file, 'r') as f:
        backup_data = json.load(f)
    
    # æ¢å¤åˆ°Notion
    notion = NotionIntegration()
    for item in backup_data:
        # è½¬æ¢ä¸ºCandidateå¯¹è±¡
        candidate = Candidate.from_notion_data(item)
        # é‡æ–°åˆ›å»ºé¡µé¢
        notion.create_candidate_page(candidate)
```

---

éƒ¨ç½²å®Œæˆåï¼Œå»ºè®®å®šæœŸæ£€æŸ¥ç³»ç»Ÿè¿è¡ŒçŠ¶æ€ï¼Œç›‘æ§æ€§èƒ½æŒ‡æ ‡ï¼Œå¹¶æ ¹æ®å®é™…ä½¿ç”¨æƒ…å†µè°ƒæ•´é…ç½®å‚æ•°ã€‚

